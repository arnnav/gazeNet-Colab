{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cvPfmdVl_6IB"
   },
   "source": [
    "# Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69HKt8_3yiAg"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import Levenshtein as Lev\n",
    "from sklearn import metrics\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from distutils.dir_util import mkpath\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 381,
     "status": "error",
     "timestamp": 1589365468603,
     "user": {
      "displayName": "Arnnav Prasad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiFaytw30iuMRDLfZFsV5zAU2bIzim22oEHCy4=s64",
      "userId": "15719712013040410618"
     },
     "user_tz": 240
    },
    "id": "soLkrirRyvFy",
    "outputId": "eea9851c-ab4a-4d8c-dc48-fabca0809ccf"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1589365468747,
     "user": {
      "displayName": "Arnnav Prasad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiFaytw30iuMRDLfZFsV5zAU2bIzim22oEHCy4=s64",
      "userId": "15719712013040410618"
     },
     "user_tz": 240
    },
    "id": "UNi7vwazHlU-",
    "outputId": "33465f61-a927-4264-a731-ee8556534931"
   },
   "outputs": [],
   "source": [
    "cd '/content/drive/My Drive/Advance Project - 523 4/Code/Eye Tracking Tool/gazeNet-Colab/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 50097,
     "status": "ok",
     "timestamp": 1588378826609,
     "user": {
      "displayName": "Arnnav Prasad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiFaytw30iuMRDLfZFsV5zAU2bIzim22oEHCy4=s64",
      "userId": "15719712013040410618"
     },
     "user_tz": 240
    },
    "id": "J8EyJmG5xE7-",
    "outputId": "08a9cd1c-c72d-409c-db98-c2be016575c4"
   },
   "outputs": [],
   "source": [
    "!pip install python-levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u0nf49rUX_rt"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def round_up_to_odd(f, min_val = 3):\n",
    "    w = np.int32(np.ceil(f) // 2 * 2 + 1)\n",
    "    w = min_val if w < min_val else w\n",
    "    return w\n",
    "\n",
    "\n",
    "def rolling_window(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "def BoxMuller_gaussian(u1,u2):\n",
    "  z1 = np.sqrt(-2*np.log(u1))*np.cos(2*np.pi*u2)\n",
    "  z2 = np.sqrt(-2*np.log(u1))*np.sin(2*np.pi*u2)\n",
    "  return z1,z2\n",
    "\n",
    "def convertToOneHot(vector, num_classes=None):\n",
    "    assert isinstance(vector, np.ndarray)\n",
    "    assert len(vector) > 0\n",
    "\n",
    "    if num_classes is None:\n",
    "        num_classes = np.max(vector)+1\n",
    "    else:\n",
    "        assert num_classes > 0\n",
    "        assert num_classes >= np.max(vector)\n",
    "\n",
    "    result = np.zeros(shape=(len(vector), num_classes))\n",
    "    result[np.arange(len(vector)), vector] = 1\n",
    "    return result.astype(int)\n",
    "\n",
    "class Config(object):\n",
    "    def __init__(self, param_file):\n",
    "        self.param_file = param_file\n",
    "        self.read_params()\n",
    "\n",
    "    class bcolors(object):\n",
    "        HEADER = '\\033[95m'\n",
    "        OKBLUE = '\\033[94m'\n",
    "        OKGREEN = '\\033[92m'\n",
    "        WARNING = '\\033[93m'\n",
    "        FAIL = '\\033[91m'\n",
    "        ENDC = '\\033[0m'\n",
    "        BOLD = '\\033[1m'\n",
    "        UNDERLINE = '\\033[4m'\n",
    "\n",
    "    def read_params(self, current_params = None):\n",
    "        with open(self.param_file, 'r') as f:\n",
    "            self.params = json.load(f, object_pairs_hook=OrderedDict)\n",
    "        if not(current_params is None) and not (current_params == self.params):\n",
    "            print (\"TRAINING PARAMETERS CHANGED\")\n",
    "            for k, p in current_params.iteritems():\n",
    "                if not(p == self.params[k]):\n",
    "                    print (self.bcolors.WARNING + \\\n",
    "                          \"%s: %s --> %s\" % (k, p, self.params[k]) + \\\n",
    "                          self.bcolors.ENDC)\n",
    "            return True\n",
    "    def save_params(self, params=None):\n",
    "        if not(params):\n",
    "            params = self.params\n",
    "        else:\n",
    "            self.params = params\n",
    "\n",
    "        with open(self.param_file, 'w') as f:\n",
    "            json.dump(params, f, indent=4)\n",
    "\n",
    "def human_format(num, suffixes=['', 'K', 'M', 'G', 'T', 'P']):\n",
    "    m = sum([abs(num/1000.0**x) >= 1 for x in range(1, len(suffixes))])\n",
    "    val = num/1000.**m\n",
    "    return '%.3f%s' % (val, suffixes[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ciwgdlJrBT5E"
   },
   "outputs": [],
   "source": [
    "class EventParser(object):\n",
    "    def __init__(self, config):\n",
    "        super(EventParser, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    def parse_data(self, sample):\n",
    "        config = self.config\n",
    "        augment = config['augment']\n",
    "        rms_noise_levels = np.arange(*config[\"augment_noise\"])\n",
    "\n",
    "        inpt_dir = ['x', 'y']\n",
    "\n",
    "        gaze_x = np.copy(sample[inpt_dir[0]])\n",
    "        gaze_y = np.copy(sample[inpt_dir[1]])\n",
    "\n",
    "        if augment:\n",
    "            u1, u2 = np.random.uniform(0,1, (2, len(sample)))\n",
    "            noise_x, noise_y = BoxMuller_gaussian(u1,u2)\n",
    "            rms_noise_level = np.random.choice(rms_noise_levels)\n",
    "            noise_x*=rms_noise_level/2\n",
    "            noise_y*=rms_noise_level/2\n",
    "            #rms = np.sqrt(np.mean(np.hypot(np.diff(noise_x), np.diff(noise_y))**2))\n",
    "            gaze_x+=noise_x\n",
    "            gaze_y+=noise_y\n",
    "\n",
    "        inpt_x, inpt_y = [np.diff(gaze_x),\n",
    "                          np.diff(gaze_y)]\n",
    "\n",
    "        X = [(_coords) for _coords in zip(inpt_x, inpt_y)]\n",
    "        X = np.array(X, dtype=np.float32)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFn-3WwF6pQz"
   },
   "outputs": [],
   "source": [
    "class EMDataset(Dataset, EventParser):\n",
    "    def __init__(self, config, gaze_data):\n",
    "\n",
    "        split_seqs = config['split_seqs']\n",
    "        #mode = config['mode']\n",
    "\n",
    "        #input is in fact diff(input), therefore we want +1 sample\n",
    "        seq_len = config['seq_len']+1\n",
    "        #seq_step = seq_len/2 if mode == 'train' else seq_len\n",
    "        seq_step = seq_len\n",
    "\n",
    "        data = []\n",
    "        #seqid = -1\n",
    "        for d in gaze_data: #iterates over files\n",
    "            dd = np.split(d, np.where(np.diff(d['status'].astype(np.int0)) != 0)[0]+1)\n",
    "            dd = [_d for _d in dd if (_d['status'].all() and not(len(_d) < seq_len))]\n",
    "\n",
    "            for seq in dd: #iterates over chunks of valid data\n",
    "                #seqid +=1\n",
    "                if split_seqs and not(len(seq) < seq_len):\n",
    "                    seqs = [seq[pos:pos + seq_len] if (pos + seq_len) < len(seq) else\n",
    "                            seq[len(seq)-seq_len:len(seq)] for pos in range(0, len(seq), seq_step)]\n",
    "                else:\n",
    "                    seqs = [seq]\n",
    "\n",
    "                data.extend(seqs)\n",
    "\n",
    "        self.data = data\n",
    "        self.size = len(data)\n",
    "        self.config = config\n",
    "\n",
    "        super(EMDataset, self).__init__(config)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        gaze_data = self.parse_data(sample)\n",
    "        evt = self.parse_evt(sample['evt'])\n",
    "\n",
    "        return torch.FloatTensor(gaze_data.T), evt, ()\n",
    "\n",
    "    def parse_evt(self, evt):\n",
    "        return evt[1:]-1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWXzZ9KpH8q6"
   },
   "outputs": [],
   "source": [
    "def _collate_fn(batch):\n",
    "    def func(p):\n",
    "        return p[0].size(1)\n",
    "\n",
    "    #return batch\n",
    "    longest_sample = max(batch, key=func)[0]\n",
    "    freq_size = longest_sample.size(0)\n",
    "    minibatch_size = len(batch)\n",
    "    max_seqlength = longest_sample.size(1)\n",
    "    inputs = torch.zeros(minibatch_size, 1, freq_size, max_seqlength)\n",
    "    input_percentages = torch.FloatTensor(minibatch_size)\n",
    "    target_sizes = [] \n",
    "    targets = []\n",
    "\n",
    "    for x in range(minibatch_size):\n",
    "        sample = batch[x]\n",
    "\n",
    "        tensor, target, (_) = sample\n",
    "        seq_length = tensor.size(1)\n",
    "        inputs[x][0].narrow(1, 0, seq_length).copy_(tensor)\n",
    "        input_percentages[x] = seq_length / float(max_seqlength)\n",
    "        target_sizes.append(len(target))\n",
    "        targets.extend(target.tolist())\n",
    "    targets = torch.LongTensor(targets)\n",
    "    return inputs, targets, input_percentages, target_sizes, (_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdlmMejvH8Qj"
   },
   "outputs": [],
   "source": [
    "class GazeDataLoader(DataLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "\n",
    "        # seed = kwargs.pop('seed', 220617)\n",
    "        super(GazeDataLoader, self).__init__(*args, **kwargs)\n",
    "        np.random.seed(seed)\n",
    "        self.collate_fn = _collate_fn\n",
    "        #self.sampler = RandomSampler(*args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rvydv2qqtM5"
   },
   "outputs": [],
   "source": [
    "def aggr_events(events_raw):\n",
    "    events_aggr = []\n",
    "    s = 0\n",
    "    for bit, group in itertools.groupby(events_raw):\n",
    "        event_length = len(list(group))\n",
    "        e = s+event_length\n",
    "        events_aggr.append([s, e, bit])\n",
    "        s = e\n",
    "    return events_aggr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6eb60FvpyVc"
   },
   "outputs": [],
   "source": [
    "class ETData():\n",
    "    #Data types and constants\n",
    "    dtype = np.dtype([\n",
    "        ('t', np.float64),\n",
    "        ('x', np.float32),\n",
    "        ('y', np.float32),\n",
    "        ('status', np.bool),\n",
    "        ('evt', np.uint8)\n",
    "    ])\n",
    "    evt_color_map = dict({\n",
    "        0: 'gray',  #0. Undefined\n",
    "        1: 'b',     #1. Fixation\n",
    "        2: 'r',     #2. Saccade\n",
    "        3: 'y',     #3. Post-saccadic oscillation\n",
    "        4: 'm',     #4. Smooth pursuit\n",
    "        5: 'k',     #5. Blink\n",
    "        9: 'k',     #9. Other\n",
    "    })\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data = np.array([], dtype=ETData.dtype)\n",
    "        self.fs = None\n",
    "        self.evt = None\n",
    "\n",
    "    def load(self, fpath, **kwargs):\n",
    "        if not('source' in kwargs):\n",
    "            try:\n",
    "                self.data = np.load(fpath)\n",
    "            except:\n",
    "                print(\"ERROR loading %s\" % fpath)\n",
    "        else:\n",
    "            if kwargs['source']=='etdata':\n",
    "                self.data = np.load(fpath)\n",
    "\n",
    "            if kwargs['source']=='array':\n",
    "                if not fpath.dtype == ETData.dtype:\n",
    "                    print (\"Error. Data types do not match\")\n",
    "                    return False\n",
    "                self.data = fpath\n",
    "\n",
    "            if kwargs['source']=='np_array':\n",
    "                self.data = np.core.records.fromarrays(fpath.T,\n",
    "                                                       dtype=ETData.dtype)\n",
    "\n",
    "            if callable(kwargs['source']):\n",
    "                self.data = kwargs['source'](fpath, ETData.dtype)\n",
    "\n",
    "        #estimate sampling rate\n",
    "        self.fs = float(self.find_nearest_fs(self.data['t']))\n",
    "        self.evt = None\n",
    "        return self.data\n",
    "\n",
    "    def save(self, spath):  \n",
    "        np.save(spath, self.data)\n",
    "\n",
    "    def find_nearest_fs(self, t):\n",
    "        fs = np.array([2000, 1250, 1000, 600, 500,  #high end\n",
    "                       300, 250, 240, 200,          #middle end\n",
    "                       120, 75, 60, 50, 30, 25])    #low end\n",
    "        ##debug\n",
    "        #if (np.diff(t) == 0).any():\n",
    "        #    stop\n",
    "        t = np.median(1/np.diff(t))\n",
    "        print(\"ETDATA-----------------------------\",t)\n",
    "        return fs.flat[np.abs(fs - t).argmin()]\n",
    "\n",
    "    def calc_evt(self, fast=False):\n",
    "        '''Calculated event data\n",
    "        '''\n",
    "        evt_compact = aggr_events(self.data['evt'])\n",
    "        evt = pd.DataFrame(evt_compact,\n",
    "                           columns = ['s', 'e', 'evt'])\n",
    "        evt['dur_s'] = np.diff(evt[['s', 'e']], axis=1).squeeze()\n",
    "        evt['dur'] = evt['dur_s']/self.fs\n",
    "\n",
    "        if not(fast):\n",
    "            evt['posx_s'], evt['posx_e'], evt['posy_s'], evt['posy_e'],\\\n",
    "            evt['posx_mean'], evt['posy_mean'], evt['posx_med'], evt['posy_med'],\\\n",
    "            evt['pv'], evt['pv_index'], evt['rms'], evt['std']   = \\\n",
    "               zip(*map(lambda x: calc_event_data(self, x), evt_compact))\n",
    "            evt['ampl_x'] = np.diff(evt[['posx_s', 'posx_e']])\n",
    "            evt['ampl_y'] = np.diff(evt[['posy_s', 'posy_e']])\n",
    "            evt['ampl'] = np.hypot(evt['ampl_x'], evt['ampl_y'])\n",
    "        #TODO:\n",
    "        #   calculate fix-to-fix saccade amplitude\n",
    "        self.evt = evt\n",
    "        return self.evt\n",
    "\n",
    "    def plot(self, spath = None, save=False, show=True, title=None):\n",
    "        '''Plots trial\n",
    "        '''\n",
    "        if show:\n",
    "            plt.ion()\n",
    "        else:\n",
    "            plt.ioff()\n",
    "\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        ax00 = plt.subplot2grid((2, 2), (0, 0))\n",
    "        ax10 = plt.subplot2grid((2, 2), (1, 0), sharex=ax00)\n",
    "        ax01 = plt.subplot2grid((2, 2), (0, 1), rowspan=2)\n",
    "\n",
    "        ax00.plot(self.data['t'], self.data['x'], '-')\n",
    "        ax10.plot(self.data['t'], self.data['y'], '-')\n",
    "        ax01.plot(self.data['x'], self.data['y'], '-')\n",
    "        for e, c in ETData.evt_color_map.iteritems():\n",
    "            mask = self.data['evt'] == e\n",
    "            ax00.plot(self.data['t'][mask], self.data['x'][mask], '.', color = c)\n",
    "            ax10.plot(self.data['t'][mask], self.data['y'][mask], '.', color = c)\n",
    "            ax01.plot(self.data['x'][mask], self.data['y'][mask], '.', color = c)\n",
    "\n",
    "        etdata_extent = np.nanmax([np.abs(self.data['x']), np.abs(self.data['y'])])+1\n",
    "\n",
    "        ax00.axis([self.data['t'].min(), self.data['t'].max(), -etdata_extent, etdata_extent])\n",
    "        ax10.axis([self.data['t'].min(), self.data['t'].max(), -etdata_extent, etdata_extent])\n",
    "        ax01.axis([-etdata_extent, etdata_extent, -etdata_extent, etdata_extent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mTHtsCsKrKtG"
   },
   "outputs": [],
   "source": [
    "def calc_k(gt, pr):\n",
    "    k = 1. if (gt == pr).all() else metrics.cohen_kappa_score(gt, pr)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Jt10KZyqHVw"
   },
   "outputs": [],
   "source": [
    "def eval_evt(etdata_gt, etdata_pr, n_events):\n",
    "\n",
    "    t = time.time()\n",
    "    if etdata_gt.evt is None:\n",
    "        etdata_gt.calc_evt(fast=True)\n",
    "    if etdata_pr.evt is None:\n",
    "        etdata_pr.calc_evt(fast=True)\n",
    "\n",
    "    #levenshtein distance\n",
    "\n",
    "    evt_gt = etdata_gt.evt['evt']\n",
    "    evt_gt = evt_gt[~(evt_gt==0)]\n",
    "    evt_pr = etdata_pr.evt['evt']\n",
    "    evt_pr = evt_pr[~(evt_pr==0)]\n",
    "    wer = Lev.distance(''.join(map(str, evt_gt)),\n",
    "                       ''.join(map(str, evt_pr)))/\\\n",
    "                       float(len(evt_gt))\n",
    "\n",
    "    _cer = map(lambda _a, _b: Lev.distance(_a, _b),\n",
    "               ''.join(map(str, etdata_gt.data['evt'])).split('0'),\n",
    "               ''.join(map(str, etdata_pr.data['evt'])).split('0'))\n",
    "    mask=etdata_gt.data['evt']==0\n",
    "    evt_len = float(sum(~mask))\n",
    "    cer = sum(_cer)/evt_len\n",
    "\n",
    "\n",
    "    #sample level K\n",
    "    t = time.time()\n",
    "    evts_gt_oh = convertToOneHot(etdata_gt.data['evt'], n_events)\n",
    "    evts_pr_oh = convertToOneHot(etdata_pr.data['evt'], n_events)\n",
    "    ks = [calc_k(evts_gt_oh[:,i], evts_pr_oh[:,i]) for i in range(1, n_events)]\n",
    "\n",
    "    evt_gt = etdata_gt.data['evt']\n",
    "    evt_gt = evt_gt[~(evt_gt==0)]\n",
    "    evt_pr = etdata_pr.data['evt']\n",
    "    evt_pr = evt_pr[~(evt_pr==0)]\n",
    "    ks_all = metrics.cohen_kappa_score(evt_gt, evt_pr)\n",
    "\n",
    "    ks.extend([ks_all])\n",
    "\n",
    "    #event level K and F1\n",
    "    try:\n",
    "        t = time.time()\n",
    "\n",
    "        ke_ = []\n",
    "        f1e_ = []\n",
    "        for evt in range(1, 4):\n",
    "            #evt=1\n",
    "            _etdata_gt = copy.deepcopy(etdata_gt)\n",
    "            mask_ext = _etdata_gt.data['evt']==0\n",
    "            mask = _etdata_gt.data['evt']==evt\n",
    "            _etdata_gt.data['evt'][mask]=1\n",
    "            _etdata_gt.data['evt'][~mask]=0\n",
    "            _etdata_gt.data['evt'][mask_ext]=255\n",
    "            _etdata_gt.calc_evt(fast=True)\n",
    "\n",
    "            _etdata_pr = copy.deepcopy(etdata_pr)\n",
    "            mask_ext = _etdata_pr.data['evt']==0\n",
    "            mask = _etdata_pr.data['evt']==evt\n",
    "            _etdata_pr.data['evt'][mask]=1\n",
    "            _etdata_pr.data['evt'][~mask]=0\n",
    "            _etdata_pr.data['evt'][mask_ext]=255\n",
    "            _etdata_pr.calc_evt(fast=True)\n",
    "\n",
    "            evt_overlap, evt_gt, evt_pr = calc_KE(_etdata_gt, _etdata_pr)\n",
    "\n",
    "            mask = (evt_gt==255) & (evt_pr==255)\n",
    "            evt_gt = evt_gt[~mask]\n",
    "            evt_pr = evt_pr[~mask]\n",
    "            ke_.append(calc_k(evt_gt, evt_pr))\n",
    "            f1e_.append(calc_f1(evt_gt, evt_pr))\n",
    "\n",
    "\n",
    "        evt_overlap, evt_gt, evt_pr = calc_KE(etdata_gt, etdata_pr)\n",
    "        mask = (evt_gt==0) & (evt_pr==0)\n",
    "        evt_gt = evt_gt[~mask]\n",
    "        evt_pr = evt_pr[~mask]\n",
    "        #print ('[overlap], dur %.2f' % (time.time()-t))\n",
    "        evt_gt_oh = convertToOneHot(evt_gt, n_events)\n",
    "        evt_pr_oh = convertToOneHot(evt_pr, n_events)\n",
    "        ke = [calc_k(evt_gt_oh[:,i], evt_pr_oh[:,i]) for i in range(1, n_events)]\n",
    "        f1e = [calc_f1(evt_gt_oh[:,i], evt_pr_oh[:,i]) for i in range(1, n_events)]\n",
    "\n",
    "        ke_all = metrics.cohen_kappa_score(evt_gt, evt_pr)\n",
    "        f1_all = metrics.f1_score(evt_gt, evt_pr, average='weighted')\n",
    "        ke.extend([ke_all])\n",
    "        ke_.extend([ke_all])\n",
    "        f1e.extend([f1_all])\n",
    "        f1e_.extend([f1_all])\n",
    "        #print ('[KE], dur %.2f' % (time.time()-t))\n",
    "    except:\n",
    "        #TODO: Debug\n",
    "        ks = [0.,]*(n_events+1)\n",
    "        ke = [0.,]*(n_events+1)\n",
    "        f1e = [0.,]*(n_events+1)\n",
    "\n",
    "    return wer, cer, ke_, ks, f1e_, (evt_overlap, evt_gt, evt_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_A3eqnJElnlw"
   },
   "outputs": [],
   "source": [
    "def run_infer(model, n_samples, data_loader, **kwargs):\n",
    "    fs = 500.\n",
    "    cuda = False if not(\"cuda\" in kwargs) else kwargs[\"cuda\"]\n",
    "    use_tqdm = False if not(\"use_tqdm\" in kwargs) else kwargs[\"use_tqdm\"]\n",
    "    perform_eval = True if not(\"eval\" in kwargs) else kwargs[\"eval\"]\n",
    "    #save_dir = None if not(kwargs.has_key(\"save_dir\")) else kwargs[\"save_dir\"]\n",
    "\n",
    "    etdata_pr = ETData()\n",
    "    etdata_gt = ETData()\n",
    "    _etdata_pr = []\n",
    "    _etdata_gt = []\n",
    "    _pr_raw=[]\n",
    "\n",
    "    sample_accum = 0\n",
    "    t = time.time()\n",
    "    iterator = tqdm(data_loader) if use_tqdm else data_loader\n",
    "    with torch.no_grad():\n",
    "        for data in iterator:\n",
    "            inputs, targets, input_percentages, target_sizes, aux = data\n",
    "\n",
    "            #do forward pass\n",
    "            # inputs = Variable(inputs, volatile=True).contiguous()\n",
    "            if cuda:\n",
    "                inputs = inputs.cuda()\n",
    "            y = model(inputs)\n",
    "            seq_length = y.size(1)\n",
    "            sizes = Variable(input_percentages.mul(int(seq_length)).int())\n",
    "\n",
    "            if cuda:\n",
    "                inputs = inputs.cpu()\n",
    "                y = y.cpu()\n",
    "                sizes = sizes.cpu()\n",
    "\n",
    "                targets = targets.cpu()\n",
    "\n",
    "            #decode output\n",
    "            outputs_split = [_y[:_l] for _y, _l in zip(y.data, target_sizes)]\n",
    "\n",
    "            events_decoded = [torch.max(_o, 1)[1].numpy().flatten() for _o in outputs_split]\n",
    "            events_target= np.array_split(targets.numpy(), np.cumsum(sizes.data.numpy())[:-1])\n",
    "\n",
    "            trials = [np.cumsum(_y[0, :, :_l], axis=1).T for _y, _l in zip(inputs.data.numpy(), target_sizes)]\n",
    "\n",
    "            for ind, (gt, pr, pr_raw, tr) in enumerate(zip(events_target, events_decoded, outputs_split, trials)):\n",
    "                #TODO:\n",
    "                #check why sizes do not match sometimes\n",
    "\n",
    "                minl = min(len(gt), len(pr))\n",
    "                gt = gt[:minl]\n",
    "                pr = pr[:minl]\n",
    "                _pr_raw.append(pr_raw.numpy())\n",
    "                #pr = np.hstack((pr[0], pr[:-1]))\n",
    "                _etdata_pr.extend(zip(np.arange(len(gt))/fs,\n",
    "                              tr[:,0],\n",
    "                              tr[:,1],\n",
    "                              itertools.repeat(True),\n",
    "                              pr+1\n",
    "                           ))\n",
    "                _etdata_pr.append((0, )*5)\n",
    "                _etdata_gt.extend(zip(np.arange(len(gt))/fs,\n",
    "                              tr[:,0],\n",
    "                              tr[:,1],\n",
    "                              itertools.repeat(True),\n",
    "                              gt+1\n",
    "                           ))\n",
    "                _etdata_gt.append((0, )*5)\n",
    "\n",
    "                sample_accum+=1\n",
    "\n",
    "            if sample_accum >= n_samples:\n",
    "                break\n",
    "        print ('[FP], n_samples: %d, dur: %.2f' % (sample_accum, time.time()-t))\n",
    "\n",
    "    if perform_eval:\n",
    "        #run evaluation\n",
    "        etdata_pr.load(np.array(_etdata_pr), **{'source':'np_array'})\n",
    "        etdata_gt.load(np.array(_etdata_gt), **{'source':'np_array'})\n",
    "        wer, cer, ke, ks, _, (evt_overlap, _, _) = eval_evt(etdata_gt, etdata_pr, 4)\n",
    "        return wer, cer, ke, ks, (_etdata_gt, _etdata_pr, _pr_raw)\n",
    "    else:\n",
    "        return _etdata_gt, _etdata_pr, _pr_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YG5HcXnvLjIl"
   },
   "outputs": [],
   "source": [
    "def checkpoint(model, step=None, epoch=None):\n",
    "    package = {\n",
    "        'epoch': epoch if epoch else 'N/A',\n",
    "        'step': step if step else 'N/A',\n",
    "        'state_dict': model.state_dict(),\n",
    "    }\n",
    "    return package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZkL9MM_IfxY"
   },
   "outputs": [],
   "source": [
    "def load(model, model_dir, config, model_name=None):\n",
    "    if len(config[\"model_name\"]) or (model_name is not None):\n",
    "        model_name = config[\"model_name\"][-1] if model_name is None else model_name\n",
    "    else:\n",
    "        model_name = None\n",
    "    # logdir = \"logdir/%s/models\" % model_dir\n",
    "    logdir = model_dir+\"/models\"\n",
    "\n",
    "\n",
    "    fpath_model = \"%s/%s\" % (logdir, model_name)\n",
    "    # print (fpath_model)\n",
    "    if os.path.exists(fpath_model) and (model_name is not None):\n",
    "        print (\"Loading model: %s\" % fpath_model)\n",
    "\n",
    "        package = torch.load(fpath_model, map_location=lambda storage, loc: storage)\n",
    "        epoch = package['epoch']+1 if not(package['epoch'] == 'N/A') else 1\n",
    "        #edit variable names for loading in cpu\n",
    "        #if not(config[\"cuda\"]):\n",
    "        for k in package['state_dict'].keys():\n",
    "            package['state_dict'][k.replace('module.', '', 1)] = package['state_dict'].pop(k)\n",
    "\n",
    "        state_dict = dict()\n",
    "        for k in model.state_dict().keys():\n",
    "            if k in package['state_dict']:\n",
    "                state_dict[k] = package['state_dict'][k]\n",
    "        model_state = model.state_dict()\n",
    "        model_state.update(state_dict)\n",
    "        model.load_state_dict(model_state)\n",
    "        print (\"done.\")\n",
    "    else:\n",
    "        epoch = 1\n",
    "        print (\"Pretrained model not found\")\n",
    "    return model_name, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nc-ev1opJ_Iw"
   },
   "outputs": [],
   "source": [
    "def save(model, model_dir, epoch, step,config):\n",
    "    logdir = model_dir+\"/models\"\n",
    "    mkpath(logdir)\n",
    "    fname_model = 'gazeNET_%04d_%08d.pth.tar' %(epoch, step)\n",
    "    file_path = '%s/%s' % (logdir, fname_model)\n",
    "\n",
    "    torch.save(checkpoint(model, step, epoch), file_path)\n",
    "    config[\"model_name\"].append(fname_model)\n",
    "    model_list = config[\"model_name\"][-config['max_to_keep']:]\n",
    "    remove_list = config[\"model_name\"][:-config['max_to_keep']:]\n",
    "    for _rm in remove_list:\n",
    "        fpath_rm = '%s/%s' % (logdir, _rm)\n",
    "        if os.path.exists(fpath_rm):\n",
    "            os.remove(fpath_rm)\n",
    "    config[\"model_name\"] = model_list\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fl99Ai1kGm4f"
   },
   "outputs": [],
   "source": [
    "def calc_params(model):\n",
    "    all_params = OrderedDict()\n",
    "    params = model.state_dict()\n",
    "\n",
    "    for _p in params.keys():\n",
    "        #if not('ih_l0_reverse' in _p):\n",
    "        all_params[_p] = params[_p].nelement()\n",
    "    return all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4YVfc1V8GR8n"
   },
   "outputs": [],
   "source": [
    "class SequenceWise(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super(SequenceWise, self).__init__()\n",
    "        self.module = module\n",
    "\n",
    "    def forward(self, x):\n",
    "        t, n = x.size(0), x.size(1)\n",
    "        x = x.view(t * n, -1)\n",
    "        x = self.module(x)\n",
    "        x = x.view(t, n, -1)\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        tmpstr = self.__class__.__name__ + ' (\\n'\n",
    "        tmpstr += self.module.__repr__()\n",
    "        tmpstr += ')'\n",
    "        return tmpstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3J2yv-mIGMFG"
   },
   "outputs": [],
   "source": [
    "class BatchRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bidirectional=False, batch_norm=True, keep_prob=0.5):\n",
    "        super(BatchRNN, self).__init__()\n",
    "        self.batch_norm = batch_norm\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        rnn_bias = False if batch_norm else True\n",
    "        self.rnn = nn.GRU(input_size=input_size,\n",
    "                          hidden_size=hidden_size,\n",
    "                          bidirectional=bidirectional,\n",
    "                          batch_first=True,\n",
    "                          bias=rnn_bias)\n",
    "        self.batch_norm_op = SequenceWise(nn.BatchNorm1d(hidden_size))\n",
    "\n",
    "        self.dropout_op = nn.Dropout(1-keep_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x)\n",
    "        x = x.contiguous()\n",
    "        if self.bidirectional:\n",
    "            x = x.view(x.size(0), x.size(1), 2, -1).sum(2).view(x.size(0), x.size(1), -1)  # (TxNxH*2) -> (TxNxH) by sum\n",
    "            x = x.contiguous()\n",
    "        if self.batch_norm:\n",
    "            x = self.batch_norm_op(x)\n",
    "        x = self.dropout_op(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FzqhulKTFvpn"
   },
   "outputs": [],
   "source": [
    "class gazeNET(nn.Module):\n",
    "    def __init__(self, config, num_classes, seed=220617):\n",
    "        super(gazeNET, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        if (torch.cuda.device_count()>0):\n",
    "            torch.cuda.manual_seed(seed)\n",
    "\n",
    "        if 'conv_stack' in config['architecture']:\n",
    "            ## convolutional stack\n",
    "            conv_config = config['architecture']['conv_stack']\n",
    "            conv_stack = []\n",
    "            #feat_dim = int(math.floor((config['sample_rate'] * 2*config['window_stride']) / 2) + 1)\n",
    "            feat_dim = 2\n",
    "            in_channels = 1\n",
    "            for _conv in conv_config:\n",
    "                name, out_channels, kernel_size, stride = _conv\n",
    "                padding = map(lambda x: int(x/2), kernel_size)\n",
    "                _conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size=tuple(kernel_size), stride=tuple(stride),\n",
    "                              padding = tuple(padding),\n",
    "                              bias = False\n",
    "                              )\n",
    "                #init_vars.xavier_uniform(conv_op.weight, gain=np.sqrt(2))\n",
    "                _conv = nn.Sequential(\n",
    "                    _conv,\n",
    "                    nn.BatchNorm2d(out_channels),\n",
    "                    nn.Hardtanh(0, 20, inplace=True),\n",
    "                    nn.Dropout(1-config['keep_prob']),\n",
    "                )\n",
    "                conv_stack.append((name, _conv))\n",
    "                in_channels = out_channels\n",
    "                feat_dim = feat_dim/stride[0]+1\n",
    "            self.conv_stack = nn.Sequential(OrderedDict(conv_stack))\n",
    "            rnn_input_size = feat_dim * out_channels\n",
    "        else:\n",
    "            self.conv_stack = None\n",
    "            rnn_input_size = 2\n",
    "\n",
    "        ## RNN stack\n",
    "        rnn_config = config['architecture']['rnn_stack']\n",
    "        rnn_stack = []\n",
    "        for _rnn in rnn_config:\n",
    "            name, hidden_size, batch_norm, bidirectional = _rnn\n",
    "            rnn_input_size=int(rnn_input_size)\n",
    "            _rnn = BatchRNN(input_size=rnn_input_size, hidden_size=hidden_size,\n",
    "                            bidirectional=bidirectional, batch_norm=batch_norm,\n",
    "                            keep_prob = config['keep_prob'])\n",
    "            rnn_stack.append((name, _rnn))\n",
    "            rnn_input_size = hidden_size\n",
    "        self.rnn_stack = nn.Sequential(OrderedDict(rnn_stack))\n",
    "\n",
    "        ## FC stack\n",
    "        self.fc = nn.Sequential(\n",
    "            SequenceWise(nn.Linear(hidden_size, num_classes, bias=False)),\n",
    "        )\n",
    "    ### forward\n",
    "    def forward(self, x):\n",
    "        if self.conv_stack is not None:\n",
    "            x = self.conv_stack(x)\n",
    "\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # Collapse feature dimension\n",
    "        x = x.transpose(1, 2).contiguous()  # TxNxH\n",
    "\n",
    "        x = self.rnn_stack(x)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puxvwzY8Vz3E"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7LpQ7GD5AB5u"
   },
   "source": [
    "### Arguments and Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zY8N5df0vvxc"
   },
   "outputs": [],
   "source": [
    "model_dir='log_dir/model_dev'\n",
    "num_workers=1\n",
    "num_epochs=20\n",
    "seed=220617\n",
    "\n",
    "\n",
    "dir_data=model_dir+'/data'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_PrXkrdVYJpu"
   },
   "source": [
    "### Config Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7QwmOQRXpfI"
   },
   "outputs": [],
   "source": [
    "configuration = Config(model_dir+'/config.json')\n",
    "config=configuration.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5zJvCxLZkdQ"
   },
   "source": [
    "### Cuda and Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NarXA8IcZj0L"
   },
   "outputs": [],
   "source": [
    "if (torch.cuda.device_count()>0) & config['cuda']:\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    batch_size*=torch.cuda.device_count()\n",
    "    cuda = True\n",
    "else:\n",
    "    batch_size = 100\n",
    "    cuda = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qu-TphLP7S50"
   },
   "source": [
    "### Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cGpsekQZopYT"
   },
   "outputs": [],
   "source": [
    "log_writer_train = tf.summary.create_file_writer(model_dir+'/TB/train')\n",
    "train_file=dir_data+'/data.gen.pkl'\n",
    "with open(train_file, 'rb') as f:\n",
    "  X_train = pickle.load(f,encoding=\"bytes\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bDtA4s0T7YM_"
   },
   "source": [
    "### Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0uy4X_in7YNA"
   },
   "outputs": [],
   "source": [
    "log_writer_val = tf.summary.create_file_writer(model_dir+'/TB/val')\n",
    "val_file=dir_data+'/data.val_clean.pkl'\n",
    "with open(val_file, 'rb') as f:\n",
    "  X_val = pickle.load(f,encoding=\"bytes\") \n",
    "  X_val = [_d for _t, _d in X_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEJwKFGy8zhV"
   },
   "source": [
    "### Load Generative Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVGCvs2U8zhW"
   },
   "outputs": [],
   "source": [
    "log_writer_train_gen = tf.summary.create_file_writer(model_dir+'/TB/train_gen')\n",
    "train_gen_file=dir_data+'/data.unpaired_clean.pkl'\n",
    "with open(train_gen_file, 'rb') as f:\n",
    "  X_train_gen = pickle.load(f,encoding=\"bytes\")\n",
    "  X_train_gen = [_d for _t, _d in X_train_gen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EqdOV7aQOGFf"
   },
   "source": [
    "### Train Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jTttxiXwV5yT"
   },
   "outputs": [],
   "source": [
    "dataset_train = EMDataset(config = config, gaze_data = X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LGOjS036ZJpw"
   },
   "outputs": [],
   "source": [
    "loader_train = GazeDataLoader(dataset_train, batch_size=batch_size,\n",
    "                              num_workers=num_workers,\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tinHb_IL6-74"
   },
   "source": [
    "### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdQqOhFZ3VIS"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "config_val = copy.deepcopy(config)\n",
    "config_val['split_seqs']=False\n",
    "config_val['batch_size']=1\n",
    "config_val['augment']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7i9T43R7J7O"
   },
   "outputs": [],
   "source": [
    "dataset_val = EMDataset(config = config_val, gaze_data = X_val)\n",
    "loader_val = GazeDataLoader(dataset_val, batch_size=1,\n",
    "                            num_workers=num_workers,\n",
    "                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O-BFAHzo_pVh"
   },
   "source": [
    "### Generative Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tI47I0Ym9TD6"
   },
   "outputs": [],
   "source": [
    "dataset_train_gen = EMDataset(config = config_val, gaze_data = X_train_gen)\n",
    "loader_train_gen = GazeDataLoader(dataset_train_gen, batch_size=1,\n",
    "                                 num_workers=num_workers,\n",
    "                                 shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlX7pvlIFMfB"
   },
   "source": [
    "### Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 75716,
     "status": "ok",
     "timestamp": 1588378852934,
     "user": {
      "displayName": "Arnnav Prasad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiFaytw30iuMRDLfZFsV5zAU2bIzim22oEHCy4=s64",
      "userId": "15719712013040410618"
     },
     "user_tz": 240
    },
    "id": "rHnVKzPZE8N5",
    "outputId": "2b2a0948-b646-4d32-de83-a2e3e8b64561"
   },
   "outputs": [],
   "source": [
    "num_classes = len(config['events'])\n",
    "model = gazeNET(config, num_classes,seed)\n",
    "# n_params = model_func.calc_params(model)\n",
    "n_params = calc_params(model)\n",
    "print(\"Number of parameters: %s\" %human_format(sum(n_params.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 85716,
     "status": "ok",
     "timestamp": 1588378862945,
     "user": {
      "displayName": "Arnnav Prasad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiFaytw30iuMRDLfZFsV5zAU2bIzim22oEHCy4=s64",
      "userId": "15719712013040410618"
     },
     "user_tz": 240
    },
    "id": "yoc5HZHHFmWj",
    "outputId": "166786a4-0687-4078-d78a-50d91a52acd0"
   },
   "outputs": [],
   "source": [
    "_, epoch_start = load(model, model_dir, config)\n",
    "\n",
    "if cuda:\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "parameters = model.parameters()\n",
    "optimizer = torch.optim.RMSprop(parameters, lr=config[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCwbnU33IZkF"
   },
   "outputs": [],
   "source": [
    "event_stats = np.array([_e for _x in X_train_gen\n",
    "                           for _e in _x['evt'].tolist()\n",
    "                           if not(len(_x)<config['seq_len']+1)])\n",
    "event_stats = convertToOneHot(event_stats-1, len(np.unique(event_stats)))\n",
    "event_weights = event_stats.sum(0)[:3]\n",
    "event_weights = event_weights.astype(np.float32)/event_weights.sum()\n",
    "weights = torch.FloatTensor(1-event_weights[:3])\n",
    "\n",
    "if cuda:\n",
    "    weights_cuda = weights.cuda()\n",
    "    criterion = torch.nn.CrossEntropyLoss(weights_cuda)\n",
    "else:\n",
    "    criterion = torch.nn.CrossEntropyLoss(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHR8SDxOJQqw"
   },
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phKar6whJUJM"
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "val_score_best = 0\n",
    "for epoch in range(epoch_start, num_epochs+1): #because we start from 1\n",
    "  # iterator = tqdm(loader_train)\n",
    "  end = time.time()\n",
    "  loss=0\n",
    "  # for step, data in enumerate(iterator):\n",
    "  for step, data in enumerate(loader_train):\n",
    "    global_step = len(loader_train)*(epoch-1) + step\n",
    "\n",
    "    ##Prepare data\n",
    "    inputs, targets, input_percentages, target_sizes, _ = data\n",
    "    t_data = time.time() - end\n",
    "\n",
    "    t_model_s = time.time()\n",
    "    inputs = Variable(inputs)\n",
    "    y_ = Variable(targets)\n",
    "    if cuda:\n",
    "        inputs = inputs.cuda()\n",
    "        y_ = y_.cuda()\n",
    "\n",
    "    ##Forward Pass\n",
    "    # print(model)\n",
    "    y = model(inputs)\n",
    "    yt, yn = y.size()[:2]\n",
    "    y = y.view(yt * yn, -1)\n",
    "    #WARNING: only works for split_seqs=True;\n",
    "    #i.e. all sequences need to be same exact length\n",
    "    loss = criterion(y, y_)\n",
    "\n",
    "    ##Backward pass\n",
    "    if torch.isnan(loss):\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm(model.parameters(), config[\"gradclip\"])\n",
    "        optimizer.step()\n",
    "    end = time.time()\n",
    "\n",
    "    # iterator.set_description('Epoch: %d, Loss: %.3f, t_data = %.3f, t_model:%.3f' % (epoch, loss.item(), t_data, end-t_model_s))\n",
    "\n",
    "    #%%model persistence\n",
    "    if not(config['save_every']==0) and (global_step%config['save_every'] == 0):\n",
    "        global_step = len(loader_train)*(epoch-1) + step\n",
    "        # model_func.save(model, args.model_dir, epoch, global_step, config)\n",
    "        save(model, model_dir, epoch, global_step, config)\n",
    "  print('Epoch: %d, Loss: %.3f, t_data = %.3f, t_model:%.3f' % (epoch, loss.item(), t_data, end-t_model_s))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "cvPfmdVl_6IB",
    "bQLm_GUoXswv",
    "CaB2DIc8VgHY",
    "XJtC4sW0FwWt",
    "puxvwzY8Vz3E",
    "7LpQ7GD5AB5u",
    "_PrXkrdVYJpu",
    "H5zJvCxLZkdQ",
    "Qu-TphLP7S50",
    "bDtA4s0T7YM_",
    "AEJwKFGy8zhV",
    "EqdOV7aQOGFf",
    "tinHb_IL6-74",
    "O-BFAHzo_pVh",
    "XlX7pvlIFMfB"
   ],
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
